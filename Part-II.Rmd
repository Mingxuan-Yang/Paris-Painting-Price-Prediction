---
title: "Part-II"
author: "Team-FP03"
date: "2019/12/10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r packages}
suppressMessages(library(knitr))
suppressMessages(library(GGally))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
suppressMessages(library(mice))
suppressMessages(library(tree))
suppressMessages(library(gbm))
suppressMessages(library(randomForest))
```

```{r read-data}
load("paintings_train.Rdata")
load("paintings_test.Rdata")
load("paintings_validation.RData")
```


```{r}
# replace blank space and NA of categorical variables with n/a
paintings_train_new <- paintings_train
paintings_train_new[, c(4, 6:9, 12:22, 25, 27:28, 30:32, 34:59)] <- as.data.frame(sapply(paintings_train_new[, c(4, 6:9, 12:22, 25, 27:28, 30:32, 34:59)], function(x) ifelse(x == "" | x == "-", "n/a", x)))

# clean position
paintings_train_new <- paintings_train_new[-which(paintings_train_new$position > 1),]

# clean Shape
paintings_train_new[which(paintings_train_new$Shape == "ronde"), 28] <- "round"
paintings_train_new[which(paintings_train_new$Shape == "ovale"), 28] <- "oval"

# choose variables
paintings_train_new <- paintings_train_new %>% 
  select(-winningbidder, -authorstandard, -sale, -lot, -price, -count, -subject, -author, -Interm, -Surface_Rect, -Surface_Rnd, -material, -materialCat, -Height_in, -Width_in, -Diam_in)

# delete repeating data
paintings_train_new <- unique(paintings_train_new)

# imputate missing
set.seed(103)
imputed <- mice(paintings_train_new, m = 5)
paintings_train_new <- mice::complete(imputed)

# clean Surface
paintings_train_new <- paintings_train_new[-which(paintings_train_new$Surface == 0),]

# clean winningbiddertype
paintings_train_new$winningbiddertype <- case_when(
      paintings_train_new$winningbiddertype == "B" ~ "B",
      paintings_train_new$winningbiddertype == "BB" ~ "B",
      paintings_train_new$winningbiddertype == "BC" ~ "B",
      paintings_train_new$winningbiddertype == "C" ~ "C",
      paintings_train_new$winningbiddertype == "D" ~ "D",
      paintings_train_new$winningbiddertype == "DB" ~ "D",
      paintings_train_new$winningbiddertype == "DC" ~ "D",
      paintings_train_new$winningbiddertype == "DD" ~ "D",
      paintings_train_new$winningbiddertype == "E" ~ "E",
      paintings_train_new$winningbiddertype == "EB" ~ "E",
      paintings_train_new$winningbiddertype == "EBC" ~ "E",
      paintings_train_new$winningbiddertype == "EC" ~ "E",
      paintings_train_new$winningbiddertype == "ED" ~ "E",
      paintings_train_new$winningbiddertype == "U" ~ "n/a",
      paintings_train_new$winningbiddertype == "n/a" ~ "n/a"
    )
paintings_train_new$winningbiddertype <- as.factor(paintings_train_new$winningbiddertype)

# log transformation to Surface
paintings_train_new$Surface <- log(paintings_train_new$Surface)
colnames(paintings_train_new)[15] <- "log_Surface"
```


# Model Mitting


## single tree
```{r}
tree.single <- tree(logprice~., data = paintings_train_new)
summary(tree.single)
```

```{r}
cv.single <- cv.tree(tree.single)
plot(cv.single$size, cv.single$dev, type = 'b')
```

```{r}
prune.single = prune.tree(tree.single, best = 13)
summary(prune.single)
```



# store prediction

## Data cleaning

```{r}
# test data
paintings_test_new <- paintings_test

# replace blank space and NA of categorical variables with n/a
paintings_test_new[, c(4, 6:9, 12:22, 25, 27:28, 30:32, 34:59)] <- as.data.frame(
  sapply(paintings_test_new[, c(4, 6:9, 12:22, 25, 27:28, 30:32, 34:59)],
         function(x) ifelse(paste(x) == "" | paste(x) == "-",
                            "n/a", paste(x))))

# clean position
paintings_test_new[which(paintings_test_new$position > 1), 3] <-
  paintings_test_new[which(paintings_test_new$position > 1), 3]/100

# clean Shape
paintings_test_new[which(paintings_test_new$Shape == "ronde"), 28] <-
  "round"
paintings_test_new[which(paintings_test_new$Shape == "ovale"), 28] <-
  "oval"

# choose variables
paintings_test_new <- paintings_test_new %>% 
  select(-winningbidder, -authorstandard, -sale, -lot, -price, -count,
         -subject, -author, -Interm, -Height_in, -Width_in, -Diam_in,
         -Surface_Rect, -Surface_Rnd, -material, -materialCat)

# clean Surface
paintings_test_new[which(paintings_test_new$Surface == 0), 15] <- NA

# imputate missing
set.seed(103)
imputed_test <- mice(paintings_test_new, m = 5)
paintings_test_new <- mice::complete(imputed_test)

# log transformation to Surface
paintings_test_new$Surface <- log(paintings_test_new$Surface)
colnames(paintings_test_new)[15] <- "log_Surface"

# clean winningbiddertype
paintings_test_new$winningbiddertype <- case_when(
      paintings_test_new$winningbiddertype == "B" ~ "B",
      paintings_test_new$winningbiddertype == "BB" ~ "B",
      paintings_test_new$winningbiddertype == "BC" ~ "B",
      paintings_test_new$winningbiddertype == "C" ~ "C",
      paintings_test_new$winningbiddertype == "D" ~ "D",
      paintings_test_new$winningbiddertype == "DB" ~ "D",
      paintings_test_new$winningbiddertype == "DC" ~ "D",
      paintings_test_new$winningbiddertype == "DD" ~ "D",
      paintings_test_new$winningbiddertype == "E" ~ "E",
      paintings_test_new$winningbiddertype == "EB" ~ "E",
      paintings_test_new$winningbiddertype == "EBC" ~ "E",
      paintings_test_new$winningbiddertype == "EC" ~ "E",
      paintings_test_new$winningbiddertype == "ED" ~ "E",
      paintings_test_new$winningbiddertype == "U" ~ "n/a",
      paintings_test_new$winningbiddertype == "n/a" ~ "n/a"
    )
paintings_test_new$winningbiddertype <- as.factor(paintings_test_new$winningbiddertype)
```



## Prediction Interval Construction

We can use some ad hoc methods to develop an interval estimate for the prediction. The bootstrap resamples from our original dataframe to simulate repeated draws from the response distributions.
This is well known to underestimate uncertainty in general. Therefore while this method allows an interval to be determined, it probably will not have the appropriate coverage we would expect.


```{r}

model <- gbm(logprice~., data = paintings_train_new, distribution = "gaussian", n.trees = 5000,
            interaction.depth=4, shrinkage=0.735)


bootstrap = function(train, fitfunct, test, iter){
  inds = replicate(iter, sample.int(nrow(train), replace = T), simplify = F) 
  resamp = lapply(inds, function(ind){train[ind,]})
  out = base::sapply(resamp, fitfunct, test) 
  return(out)
}


fit <- function(tr, te) {
  model <- gbm(logprice~., data = tr, distribution = "gaussian", n.trees = 5000,
            interaction.depth=4, shrinkage=0.735)
  out <- predict(model, te, n.trees=5000)
}


boot.boost <- bootstrap(train = paintings_train_new, 
                         fitfunct = fit, 
                         test = paintings_test_new, 
                         iter = 20)



```

```{r}
CI <- t(apply(boot.boost, MARGIN = 1, quantile, c(0.025, 0.975)))
ind <- which(colnames(paintings_train_new)=='logprice')
yhat.train <- predict(model, newdata = paintings_train_new[,-ind], n.trees = 5000)
rmse.train <- mean((paintings_train_new[,ind] - yhat.train)^2)
PI <- cbind(CI[,1]-rmse.train, CI[,2] + rmse.train)
```


```{r}
as.data.frame(rf$importance) %>% arrange(IncNodePurity)
```



```{r}
rf <- randomForest(logprice~., data = paintings_train_new,
            importance = TRUE)


bootstrap = function(train, fitfunct, test, iter){
  inds = replicate(iter, sample.int(nrow(train), replace = T), simplify = F) 
  resamp = lapply(inds, function(ind){train[ind,]})
  out = base::sapply(resamp, fitfunct, test) 
  return(out)
}


fit.rf <- function(tr, te) {
  model <- randomForest(logprice~., data = tr, importance = TRUE)
  out <- predict(model, te)
}


boot.boost <- bootstrap(train = paintings_train_new, 
                         fitfunct = fit.rf, 
                         test = paintings_test_new, 
                         iter = 20)

```







```{r}
CI <- t(apply(boot.boost, MARGIN = 1, quantile, c(0.025, 0.975)))
ind <- which(colnames(paintings_train_new)=='logprice')
yhat.train <- predict(model, newdata = paintings_train_new[,-ind], n.trees = 5000)
rmse.train <- mean((paintings_train_new[,ind] - yhat.train)^2)
PI <- cbind(CI[,1]-rmse.train, CI[,2] + rmse.train)
```


```{r predict-model-final, echo=FALSE, include=FALSE}
# change model1 or update as needed
fit = exp(apply(boot.boost, MARGIN = 1, FUN = mean))
lwr = exp(PI[,1])
upr = exp(PI[,2])

predictions <- data.frame(fit = fit, lwr = lwr, upr = upr)
save(predictions, file="predict-test.Rdata")
```

